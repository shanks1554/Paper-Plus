{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7335ec0",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5694c655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ab7b3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "assert HF_TOKEN is not None, \"HF_TOKEN not found in environment\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b98cde",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "978e2bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_classic.chains import RetrievalQA\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f401022",
   "metadata": {},
   "source": [
    "## Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9850a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Deep\\AppData\\Local\\Temp\\ipykernel_14736\\118603400.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24905dc1",
   "metadata": {},
   "source": [
    "## Domain -> Vector Index Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55a3174a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOMAIN_INDEX_PATHS = {\n",
    "    \"artificial_intelligence\": \"../indexes/artificial_intelligence\",\n",
    "    \"medical\": \"../indexes/medical\",\n",
    "    \"climate\": \"../indexes/climate\",\n",
    "    \"cyber_security\": \"../indexes/cyber_security\",\n",
    "    \"business\": \"../indexes/business\",\n",
    "    \"psychology\": \"../indexes/psychology\",\n",
    "    \"automobile\": \"../indexes/automobile\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5738a67",
   "metadata": {},
   "source": [
    "## Domain-Specific Retrieval Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2aa48151",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOMAIN_K = {\n",
    "    \"artificial_intelligence\": 16,\n",
    "    \"medical\": 12,\n",
    "    \"cyber_security\": 14,\n",
    "    \"climate\": 12,\n",
    "    \"business\": 10,\n",
    "    \"psychology\": 10,\n",
    "    \"automobile\": 8\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c17537a",
   "metadata": {},
   "source": [
    "## Load FAISS Database for a Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09ff9786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vector_db(domain: str):\n",
    "    if domain not in DOMAIN_INDEX_PATHS:\n",
    "        raise ValueError(f\"Unsupported domain: {domain}\")\n",
    "    \n",
    "    return FAISS.load_local(\n",
    "        DOMAIN_INDEX_PATHS[domain],\n",
    "        embedding_model,\n",
    "        allow_dangerous_deserialization=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8eee4f",
   "metadata": {},
   "source": [
    "## RAG Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f9a2b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_PROMPT_TEMPLATE = \"\"\"\n",
    "Use the pieces of information provided in the context to answer the user's question.\n",
    "If you do not know the answer, say that you do not know.\n",
    "Do not make up an answer.\n",
    "Do not use information outside the given context.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer directly. No small talk.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "116f3df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template = CUSTOM_PROMPT_TEMPLATE,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e04478",
   "metadata": {},
   "source": [
    "## Hugging Face Interface Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae554e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = InferenceClient(\n",
    "    model = \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    token = HF_TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333d179e",
   "metadata": {},
   "source": [
    "## LLM Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "663ed8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hf_llm_call(prompt: str, **kwargs) -> str:\n",
    "    if hasattr(prompt, \"to_string\"):\n",
    "        prompt = prompt.to_string()\n",
    "    \n",
    "    response = client.chat_completion(\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens = 512,\n",
    "        temperature = 0.2\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6433289",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = RunnableLambda(hf_llm_call)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2e22c8",
   "metadata": {},
   "source": [
    "## Create Domain Specific QA Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67af7064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qa_chain(domain: str):\n",
    "    db = load_vector_db(domain)\n",
    "    k = DOMAIN_K.get(domain, 10)\n",
    "    \n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm = llm,\n",
    "        chain_type = \"stuff\",\n",
    "        retriever = db.as_retriever(search_kwargs={\"k\": k}),\n",
    "        return_source_documents = True,\n",
    "        chain_type_kwargs = {\"prompt\": prompt}\n",
    "    )\n",
    "    return qa_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad61609",
   "metadata": {},
   "source": [
    "## Unified Question Answering Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6e6e253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question: str, domain: str):\n",
    "    qa_chain = create_qa_chain(domain)\n",
    "    response = qa_chain.invoke({\"query\": question})\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a862c21c",
   "metadata": {},
   "source": [
    "## Test - Artificial Intelligence Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d446e0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the recent research trends in Artificial Intelligence?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f143ba62",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = answer_question(\n",
    "    question = query,\n",
    "    domain = \"artificial_intelligence\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f76d6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANSWER:\n",
      " The recent research trends in Artificial Intelligence include:\n",
      "\n",
      "1. Exponential growth in the number of publications on AI, with a nearly 20-fold increase from 7 papers in 2014 to 200 papers in 2024.\n",
      "2. A deepening research focus in the field of AI, with a significant increase in the number of publications in the years 2019-2024.\n",
      "3. The development of new applications of AI, such as speech recognition systems, inventory control systems, surveillance systems, robots, and search engines.\n",
      "4. The creation of new jobs in machine learning, data science, and other related fields.\n",
      "5. The growth of new businesses and investment opportunities due to the endless applications of AI in various fields, including agriculture, education, transportation, finance, biotechnology, cybersecurity, and gaming.\n",
      "\n",
      "These trends indicate a significant increase in research and development in the field of AI, with a focus on creating new applications and opportunities.\n",
      "\n",
      "SOURCES:\n",
      "AI computer science 4.pdf\n",
      "AI computer science 1.pdf\n",
      "AI computer science 1.pdf\n",
      "AI computer science 4.pdf\n",
      "3727353.3727478.pdf\n",
      "AI computer science 5.pdf\n",
      "AI computer science 5.pdf\n",
      "AI computer science 5.pdf\n",
      "AI computer science 5.pdf\n",
      "AI computer science 5.pdf\n",
      "AI computer science 5.pdf\n",
      "AI computer science 4.pdf\n",
      "AI computer science 4.pdf\n",
      "AI computer science 5.pdf\n",
      "AI computer science 5.pdf\n",
      "AI computer science 5.pdf\n"
     ]
    }
   ],
   "source": [
    "print(\"ANSWER:\\n\", response[\"result\"])\n",
    "print(\"\\nSOURCES:\")\n",
    "for doc in response[\"source_documents\"]:\n",
    "    print(doc.metadata.get(\"source\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c3360f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANSWER:\n",
      " According to the provided context, common cyber security attack vectors include:\n",
      "\n",
      "1. Phishing: a practice of fooling individuals into exposing sensitive information by employing dishonest methods, such as bogus emails, websites, or ideas.\n",
      "2. Malware: a hateful operating system, such as viruses, worms, Trojan stallions, ransomware, spyware, or adware, that aims to penetrate calculating systems, steal data, restrict workflow, or cause harm.\n",
      "3. DDoS & DoS Attack: a type of attack that aims to classify network traces as normal or anomalous, and can be used to overwhelm a system or network with traffic, making it difficult to function.\n",
      "4. Social engineering: an action taken by opponents to deceive individuals into revealing sensitive information, which can be used to make them more inclined to click on links, spread malware, or support distressing causes.\n"
     ]
    }
   ],
   "source": [
    "query = \"What are common cyber security attack vectors?\"\n",
    "\n",
    "response = answer_question(\n",
    "    question=query,\n",
    "    domain=\"cyber_security\"\n",
    ")\n",
    "\n",
    "print(\"ANSWER:\\n\", response[\"result\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
